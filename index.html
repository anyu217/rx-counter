<!DOCTYPE html>
<html lang="zh-Hant">
<head>
  <meta charset="UTF-8">
  <title>YOLOv8 ONNX JS 藥錠偵測計數器</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
  <style>
    body { font-family: Arial; text-align:center; background:#fafafa; }
    h1 { background:#007B83; color:#fff; padding:10px; }
    video,canvas { width:90vw; max-width:600px; border:2px solid #007B83; border-radius:8px; }
    #count { font-size:1.5em; color:green; margin-top:10px; }
  </style>
</head>
<body>
  <h1>YOLOv8 ONNX JS 藥錠偵測計數器</h1>
  <video id="video" autoplay muted playsinline></video>
  <canvas id="canvas"></canvas>
  <div id="count">載入模型中...</div>

<script>
const video = document.getElementById('video');
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d');
const countDisplay = document.getElementById('count');
let session;

async function setupCamera() {
  const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" } });
  video.srcObject = stream;
  return new Promise(res => { video.onloadedmetadata = () => { 
    canvas.width = video.videoWidth; canvas.height = video.videoHeight; res(); }; });
}

async function loadModel() {
  session = await ort.InferenceSession.create("yolov8n.onnx");
  countDisplay.textContent = "模型載入完成，開始辨識...";
}

async function detect() {
  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
  let fakeDetections = [ {x:100,y:100}, {x:200,y:150} ]; // 模擬
  let count = fakeDetections.length;
  fakeDetections.forEach(det => {
    ctx.beginPath(); ctx.arc(det.x, det.y, 6, 0, 2*Math.PI);
    ctx.fillStyle="lime"; ctx.fill();
  });
  countDisplay.textContent = `偵測數量：${count}`;
  requestAnimationFrame(detect);
}

(async () => { await setupCamera(); await loadModel(); detect(); })();
</script>
</body>
</html>